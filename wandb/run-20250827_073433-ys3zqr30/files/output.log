[2025-08-27 07:34:34] Starting Dual Adapter GRPO Training
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]
[2025-08-27 07:34:40] Loading Data
[2025-08-27 07:34:40] Training samples: 1520, Validation samples: 190
[2025-08-27 07:34:40] === Data Samples ===
[2025-08-27 07:34:40] Sample Keys: ['id', 'input', 'output']
[2025-08-27 07:34:40] Sample Premise: 또한 ‘브람스를 좋아하세요?’는 SBS 단편드라마 ‘17세의 조건’으로 감각적 연출을 선보인 조영민 감독과 섬세한 필력을 자랑한 류보리 작가가 의기투합해 웰메이드 작품 탄생을 예고하고 있다. 박은빈과 김민재의 신선한 조합에, SBS 기대주 감독과 작가가 가세한 SBS 새 월화드라마 ‘브람스를 좋아하세요?’는 8월 31일에 첫 방송된다.
[2025-08-27 07:34:40] Sample Proposition: 박은빈이 출연한 SBS 월화 드라마의 제목에는 작곡가 이름이 들어간다.
[2025-08-27 07:34:40] Sample Label: entailment
[2025-08-27 07:34:40] Sample Reference Output: '브람스를 좋아하세요?'에 독일 작곡가인 브람스의 이름이 들어가 있다. 따라서 가설 문장은 함의에 해당한다.
[2025-08-27 07:34:40] ===================
[2025-08-27 07:34:40] Creating LoRA Adapters
/home/nlplab/anaconda3/envs/soeon/lib/python3.10/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.
  warnings.warn(
/home/nlplab/anaconda3/envs/soeon/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!
  warnings.warn(
[2025-08-27 07:34:40] Training Adapter A(ROUGE Optimizer)
[2025-08-27 07:34:40] Reference Map Size: 1
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
[2025-08-27 07:34:42] Starting Adapter A Training
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|          | 0/36480 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/media/nlplab/hdd1/hclt_ss/grpo/main.py", line 119, in <module>
    main()
  File "/media/nlplab/hdd1/hclt_ss/grpo/main.py", line 78, in main
    adapter_a = train_adapter_a(
  File "/media/nlplab/hdd1/hclt_ss/grpo/train.py", line 311, in train_adapter_a
    trainer.train()
  File "/home/nlplab/anaconda3/envs/soeon/lib/python3.10/site-packages/transformers/trainer.py", line 2206, in train
    return inner_training_loop(
  File "/home/nlplab/anaconda3/envs/soeon/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/nlplab/anaconda3/envs/soeon/lib/python3.10/site-packages/transformers/trainer.py", line 3743, in training_step
    inputs = self._prepare_inputs(inputs)
  File "/home/nlplab/anaconda3/envs/soeon/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/home/nlplab/anaconda3/envs/soeon/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1279, in _prepare_inputs
    generation_batch = self._generate_and_score_completions(generation_batch)
  File "/home/nlplab/anaconda3/envs/soeon/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1677, in _generate_and_score_completions
    rewards_per_func = self._calculate_rewards(inputs, original_prompts, completions, completion_ids_list)
  File "/home/nlplab/anaconda3/envs/soeon/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/home/nlplab/anaconda3/envs/soeon/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1321, in _calculate_rewards
    output_reward_func = reward_func(
  File "/media/nlplab/hdd1/hclt_ss/grpo/train.py", line 282, in adapter_a_reward_function
    reward = compute_adapter_a_reward(
NameError: name 'compute_adapter_a_reward' is not defined
